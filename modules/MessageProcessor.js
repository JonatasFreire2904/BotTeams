const LLMService = require("../services/LLMService");

class MessageProcessor {
  constructor() {
    this.llmService = new LLMService();
  }

  carregarPromptAtualizado() {
    this.llmService.carregarPromptAtualizado();
  }

  async gerarResposta(mensagem, autor) {
    try {
      console.log(`ğŸ§  Gerando resposta com LLM para: "${mensagem}"`);
      const bruta = await this.llmService.gerarResposta(mensagem);
      if (!bruta) return null;

      // Remove prefixos como "LM:", "IA:", "Resposta:"
      const resposta = bruta.replace(/^(LM|IA|BOT|Resposta)[:ï¼š]?\s*/i, '').trim();

      // ValidaÃ§Ã£o contra regras do prompt
      if (
        resposta.split(/\s+/).length > 10 || // mais de 10 palavras
        /(?:IA|modelo|inteligÃªncia artificial|sou uma IA|sou um modelo|assistente|language model)/i.test(resposta)
      ) {
        console.warn(`â›” Resposta invÃ¡lida detectada e bloqueada: "${resposta}"`);
        return null;
      }

      return resposta;
    } catch (err) {
      console.error("âŒ Erro ao processar mensagem com LLM:", err);
      return null;
    }
  }
}

module.exports = MessageProcessor;
